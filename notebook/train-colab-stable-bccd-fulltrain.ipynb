{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train-colab-stable-bccd-fulltrain.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0bVtSWKRUp7q","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MRDGiFNUyeZ5","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/yolo-v4-tf.keras')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3tVRS6-ybFh","colab_type":"code","colab":{}},"source":["import cv2\n","import numpy as np\n","from utils import DataGenerator, preprocess_true_boxes\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K\n","import tensorflow as tf\n","import math\n","from models import Yolov4, yolov4_head, get_boxes, nms\n","from config import yolo_config\n","from loss import *\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SSIg2-CJy5NY","colab_type":"code","colab":{}},"source":["with open('/content/drive/My Drive/yolo-v4-tf.keras/dataset/train_txt/anno2.txt') as f:\n","# with open('/content/drive/My Drive/yolo-v4-tf.keras/dataset/train_txt/anno.txt') as f:\n","    lines = f.readlines()\n","lines = lines[:]\n","# lines = lines * 8\n","# print(lines)\n","# lines = lines * 32\n","\n","NUM_CLASS = 3\n","FOLDER_PATH = '/content/drive/My Drive/yolo-v4-tf.keras'\n","BS = 8\n","anchors = np.array([12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401]).reshape((-1, 2))\n","\n","data_gen = DataGenerator(lines[:], BS, (416, 416), num_classes=NUM_CLASS, folder_path=FOLDER_PATH, anchors=anchors)\n","model = Yolov4(\n","                weight_path=None,\n","                class_name_path='/content/drive/My Drive/yolo-v4-tf.keras/bccd_classes.txt'\n","            #    class_name_path='/content/drive/My Drive/yolo-v4-tf.keras/coco_classes.txt',\n","#               weight_path='yolov4.weights',\n","#                img_size=(416, 416, 3),\n","              )\n","model.build_model(load_pretrained=False)\n","\n","print('num class : ', model.num_classes)\n","\n","# model2 = tf.keras.models.load_model('/content/drive/My Drive/bccd.h5', compile=False)\n","# model.yolo_model = \n","# yolov4_output = yolov4_head(self.yolo_model.output, self.num_classes, self.anchors, self.xyscale)\n","# self.inference_model = models.Model(self.yolo_model.input,\n","#                                     nms(yolov4_output, self.img_size, self.num_classes))  # [boxes, scores, classes, valid_detections]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DfmZzGK9G5_F","colab_type":"code","colab":{}},"source":["# model.yolo_model.load_weights('/content/drive/My Drive/yolo-v4-tf.keras/bccd.h5', by_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uPLeCW8uzEso","colab_type":"code","colab":{}},"source":["y_true = [\n","    tf.keras.layers.Input(name='input_2', shape=(52, 52, 3, (NUM_CLASS + 5))),  # label_sbbox\n","    tf.keras.layers.Input(name='input_3', shape=(26, 26, 3, (NUM_CLASS + 5))),  # label_mbbox\n","    tf.keras.layers.Input(name='input_4', shape=(13, 13, 3, (NUM_CLASS + 5))),  # label_lbbox\n","    tf.keras.layers.Input(name='input_5', shape=(100, 4)),             # true_bboxes\n","]\n","loss_list = tf.keras.layers.Lambda(yolo_loss, name='yolo_loss',\n","                        arguments={'num_classes': NUM_CLASS, 'iou_loss_thresh': 0.5,\n","                                    'anchors': anchors.reshape((3, 3, 2))})([*model.yolo_model.output, *y_true])\n","model2 = tf.keras.models.Model([model.yolo_model.input, *y_true], loss_list)\n","\n","model2.compile(loss={'yolo_loss': lambda y_true, y_pred: y_pred}, optimizer=tf.keras.optimizers.Adam(lr=1e-3))\n","logs = np.array([])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7lYUkoAzH0c","colab_type":"code","colab":{}},"source":["model2.fit(data_gen, \n","           initial_epoch=0,\n","           epochs=1000, \n","            callbacks=[tf.keras.callbacks.ModelCheckpoint('/content/drive/My Drive/bccd.h5', save_best_only=True, save_weights_only=True, monitor='loss')],\n","           )\n","# for epoch in range(50):\n","#     for x_batch, y_batch_tensor, y_batch_bbox in data_gen:\n","#         y_true = [np.zeros(BS)]\n","#         # print('train on batch ', y_batch_tensor[0].shape)\n","#         losses = model2.train_on_batch([x_batch, *y_batch_tensor, y_batch_bbox], y_true)\n","#         loss = losses\n","# #         if len(logs) > 0 and loss < np.min(logs):\n","# #             model.yolo_model.save('/content/drive/My Drive/yolov4-giou.h5')\n","#         logs = np.append(logs, loss)\n","#     print(f'epoch {epoch} losses ' , logs[-1])\n","#         # train_step(x_batch, y_batch_tensor, y_batch_bbox)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2psIOo2j3L4N","colab_type":"code","colab":{}},"source":["# model.yolo_model.save('loss125.h5')\n","model.yolo_model.load_weights('/content/drive/My Drive/yolo-v4-tf.keras/bccd.h5', by_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bLWvcafSz2SF","colab_type":"code","colab":{}},"source":["# x_batch, y_true = data_gen.__getitem__(0)\n","# y_true = [np.zeros(BS), np.zeros(BS), np.zeros(BS)]\n","# y_true = [np.zeros(BS)]\n","# loss = model2.predict([x_batch, *y_batch_tensor, y_batch_bbox])\n","# loss2 = model2.evaluate(x_batch, y_true)\n","loss2 = model2.evaluate(data_gen)\n","print(loss2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aPjVLKXb0AWH","colab_type":"code","colab":{}},"source":["model.predict('/content/drive/My Drive/yolo-v4-tf.keras/dataset/train_img2/test3.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"329jjLqQ1eN0","colab_type":"code","colab":{}},"source":["i = np.random.randint(len(lines))\n","path = '/content/drive/My Drive/yolo-v4-tf.keras/' + lines[i].split(' ')[0] # f'/content/drive/My Drive/yolo-v4-tf.keras/dataset/train_img/BloodImage_00372.jpg'\n","print(path)\n","# model.predict(path)\n","model.predict_nonms(path, iou_threshold=0.4, score_threshold=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAvKXwc3lp2f","colab_type":"code","colab":{}},"source":["#!/usr/bin/env python\n","# coding: utf-8\n","\n","\n","\n","import cv2\n","import numpy as np\n","from utils import DataGenerator, preprocess_true_boxes\n","import matplotlib.pyplot as plt\n","import tensorflow.keras.backend as K\n","import tensorflow as tf\n","import math\n","\n","from models import Yolov4, yolov4_head, get_boxes\n","from config import yolo_config\n","\n","print(tf.__version__)\n","# In[3]:\n","\n","\n","# with open('/content/drive/My Drive/yolo-v4-tf.keras/dataset/train_txt/anno2.txt') as f:\n","with open('/content/drive/My Drive/yolo-v4-tf.keras/dataset/train_txt/anno.txt') as f:\n","    lines = f.readlines()\n","lines = lines[:1]\n","# lines = lines * 8\n","print(lines)\n","# lines = lines * 32\n","\n","# In[4]:\n","\n","NUM_CLASS = 80\n","FOLDER_PATH = '/content/drive/My Drive/yolo-v4-tf.keras'\n","BS = 1\n","anchors = np.array([12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401]).reshape((-1, 2))\n","\n","\n","# In[6]:\n","\n","\n","data_gen = DataGenerator(lines[:], BS, (416, 416), num_classes=NUM_CLASS, folder_path=FOLDER_PATH, anchors=anchors)\n","\n","\n","\n","model = Yolov4(\n","                weight_path=None,\n","                # class_name_path='/content/drive/My Drive/yolo-v4-tf.keras/bccd_classes.txt'\n","               class_name_path='/content/drive/My Drive/yolo-v4-tf.keras/coco_classes.txt',\n","#               weight_path='yolov4.weights',\n","\n","#                img_size=(416, 416, 3),\n","            \n","              )\n","model.build_model(load_pretrained=False)\n","# model.load_model('/content/drive/My Drive/yolov4-giou.h5')\n","print('num class : ', model.num_classes)\n","\n","\n","\n","# In[29]:\n","\n","\n","# from tflite yolov4\n","def bbox_giou(bboxes1, bboxes2):\n","    \"\"\"\n","    Generalized IoU\n","    @param bboxes1: (a, b, ..., 4)\n","    @param bboxes2: (A, B, ..., 4)\n","        x:X is 1:n or n:n or n:1\n","    @return (max(a,A), max(b,B), ...)\n","    ex) (4,):(3,4) -> (3,)\n","        (2,1,4):(2,3,4) -> (2,3)\n","    \"\"\"\n","    bboxes1_area = bboxes1[..., 2] * bboxes1[..., 3]\n","    bboxes2_area = bboxes2[..., 2] * bboxes2[..., 3]\n","\n","    bboxes1_coor = tf.concat(\n","        [\n","            bboxes1[..., :2] - bboxes1[..., 2:] * 0.5,\n","            bboxes1[..., :2] + bboxes1[..., 2:] * 0.5,\n","        ],\n","        axis=-1,\n","    )\n","    bboxes2_coor = tf.concat(\n","        [\n","            bboxes2[..., :2] - bboxes2[..., 2:] * 0.5,\n","            bboxes2[..., :2] + bboxes2[..., 2:] * 0.5,\n","        ],\n","        axis=-1,\n","    )\n","\n","    left_up = tf.maximum(bboxes1_coor[..., :2], bboxes2_coor[..., :2])\n","    right_down = tf.minimum(bboxes1_coor[..., 2:], bboxes2_coor[..., 2:])\n","\n","    inter_section = tf.maximum(right_down - left_up, 0.0)\n","    inter_area = inter_section[..., 0] * inter_section[..., 1]\n","\n","    union_area = bboxes1_area + bboxes2_area - inter_area\n","\n","    iou = tf.math.divide_no_nan(inter_area, union_area)\n","\n","    enclose_left_up = tf.minimum(bboxes1_coor[..., :2], bboxes2_coor[..., :2])\n","    enclose_right_down = tf.maximum(\n","        bboxes1_coor[..., 2:], bboxes2_coor[..., 2:]\n","    )\n","\n","    enclose_section = enclose_right_down - enclose_left_up\n","    enclose_area = enclose_section[..., 0] * enclose_section[..., 1]\n","\n","    giou = iou - tf.math.divide_no_nan(enclose_area - union_area, enclose_area)\n","\n","    return giou\n","def bbox_ciou(boxes1, boxes2):\n","    '''\n","    计算ciou = iou - p2/c2 - av\n","    :param boxes1: (8, 13, 13, 3, 4)   pred_xywh\n","    :param boxes2: (8, 13, 13, 3, 4)   label_xywh\n","    :return:\n","\n","    举例时假设pred_xywh和label_xywh的shape都是(1, 4)\n","    '''\n","\n","    # 变成左上角坐标、右下角坐标\n","    boxes1_x0y0x1y1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n","                                 boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n","    boxes2_x0y0x1y1 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n","                                 boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n","    '''\n","    逐个位置比较boxes1_x0y0x1y1[..., :2]和boxes1_x0y0x1y1[..., 2:]，即逐个位置比较[x0, y0]和[x1, y1]，小的留下。\n","    比如留下了[x0, y0]\n","    这一步是为了避免一开始w h 是负数，导致x0y0成了右下角坐标，x1y1成了左上角坐标。\n","    '''\n","    boxes1_x0y0x1y1 = tf.concat([tf.minimum(boxes1_x0y0x1y1[..., :2], boxes1_x0y0x1y1[..., 2:]),\n","                                 tf.maximum(boxes1_x0y0x1y1[..., :2], boxes1_x0y0x1y1[..., 2:])], axis=-1)\n","    boxes2_x0y0x1y1 = tf.concat([tf.minimum(boxes2_x0y0x1y1[..., :2], boxes2_x0y0x1y1[..., 2:]),\n","                                 tf.maximum(boxes2_x0y0x1y1[..., :2], boxes2_x0y0x1y1[..., 2:])], axis=-1)\n","\n","    # 两个矩形的面积\n","    boxes1_area = (boxes1_x0y0x1y1[..., 2] - boxes1_x0y0x1y1[..., 0]) * (\n","                boxes1_x0y0x1y1[..., 3] - boxes1_x0y0x1y1[..., 1])\n","    boxes2_area = (boxes2_x0y0x1y1[..., 2] - boxes2_x0y0x1y1[..., 0]) * (\n","                boxes2_x0y0x1y1[..., 3] - boxes2_x0y0x1y1[..., 1])\n","\n","    # 相交矩形的左上角坐标、右下角坐标，shape 都是 (8, 13, 13, 3, 2)\n","    left_up = tf.maximum(boxes1_x0y0x1y1[..., :2], boxes2_x0y0x1y1[..., :2])\n","    right_down = tf.minimum(boxes1_x0y0x1y1[..., 2:], boxes2_x0y0x1y1[..., 2:])\n","\n","    # 相交矩形的面积inter_area。iou\n","    inter_section = tf.maximum(right_down - left_up, 0.0)\n","    inter_area = inter_section[..., 0] * inter_section[..., 1]\n","    union_area = boxes1_area + boxes2_area - inter_area\n","    iou = inter_area / (union_area + 1e-9)\n","\n","    # 包围矩形的左上角坐标、右下角坐标，shape 都是 (8, 13, 13, 3, 2)\n","    enclose_left_up = tf.minimum(boxes1_x0y0x1y1[..., :2], boxes2_x0y0x1y1[..., :2])\n","    enclose_right_down = tf.maximum(boxes1_x0y0x1y1[..., 2:], boxes2_x0y0x1y1[..., 2:])\n","\n","    # 包围矩形的对角线的平方\n","    enclose_wh = enclose_right_down - enclose_left_up\n","    enclose_c2 = K.pow(enclose_wh[..., 0], 2) + K.pow(enclose_wh[..., 1], 2)\n","\n","    # 两矩形中心点距离的平方\n","    p2 = K.pow(boxes1[..., 0] - boxes2[..., 0], 2) + K.pow(boxes1[..., 1] - boxes2[..., 1], 2)\n","\n","    # 增加av。加上除0保护防止nan。\n","    atan1 = tf.atan(boxes1[..., 2] / (boxes1[..., 3] + 1e-9))\n","    atan2 = tf.atan(boxes2[..., 2] / (boxes2[..., 3] + 1e-9))\n","    v = 4.0 * K.pow(atan1 - atan2, 2) / (math.pi ** 2)\n","    a = v / (1 - iou + v)\n","\n","    ciou = iou - 1.0 * p2 / enclose_c2 - 1.0 * a * v\n","    return ciou\n","def bbox_iou(boxes1, boxes2):\n","    boxes1_area = boxes1[..., 2] * boxes1[..., 3]  # 所有格子的3个预测框的面积\n","    boxes2_area = boxes2[..., 2] * boxes2[..., 3]  # 所有ground truth的面积\n","\n","    # (x, y, w, h)变成(x0, y0, x1, y1)\n","    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n","                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n","    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n","                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n","\n","    # 所有格子的3个预测框 分别 和  70个ground truth  计算iou。 所以left_up和right_down的shape = (?, grid_h, grid_w, 3, 70, 2)\n","    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])  # 相交矩形的左上角坐标\n","    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])  # 相交矩形的右下角坐标\n","\n","    inter_section = tf.maximum(right_down - left_up, 0.0)  # 相交矩形的w和h，是负数时取0     (?, grid_h, grid_w, 3, 70, 2)\n","    inter_area = inter_section[..., 0] * inter_section[..., 1]  # 相交矩形的面积            (?, grid_h, grid_w, 3, 70)\n","    union_area = boxes1_area + boxes2_area - inter_area  # union_area      (?, grid_h, grid_w, 3, 70)\n","    iou = 1.0 * inter_area / (union_area + 1e-9)  # iou                             (?, grid_h, grid_w, 3, 70)\n","    return iou\n","\n","def yolo_loss_wrapper(input_shape, STRIDES, NUM_CLASS, ANCHORS, XYSCALES, IOU_LOSS_THRESH):\n","    input_shape = input_shape[0]\n","    def yolo_loss(label, y_pred, y_batch_box):\n","        bboxes = decode_train2(y_pred, input_shape // STRIDES, NUM_CLASS, STRIDES, ANCHORS, XYSCALES)\n","        \n","        conv_shape = tf.shape(y_pred)\n","        batch_size = conv_shape[0]\n","        output_size = conv_shape[1]\n","        input_size = STRIDES * output_size\n","        # conv = tf.reshape(conv, (batch_size, output_size, output_size,\n","        #                          3, 5 + num_class))\n","        conv_raw_prob = bboxes[:, :, :, :, 5:]\n","\n","        pred_xywh = bboxes[:, :, :, :, 0:4]\n","        pred_conf = bboxes[:, :, :, :, 4:5]\n","\n","        label_xywh = label[:, :, :, :, 0:4]\n","        respond_bbox = label[:, :, :, :, 4:5]\n","        label_prob = label[:, :, :, :, 5:]\n","\n","        ciou = tf.expand_dims(bbox_giou(pred_xywh, label_xywh), axis=-1)  # (8, 13, 13, 3, 1)\n","        # ciou = tf.expand_dims(bbox_ciou(pred_xywh, label_xywh), axis=-1)  # (8, 13, 13, 3, 1)\n","        input_size = tf.cast(input_size, tf.float32)\n","\n","        # 每个预测框xxxiou_loss的权重 = 2 - (ground truth的面积/图片面积)\n","        bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2)\n","        ciou_loss = respond_bbox * bbox_loss_scale * (1 - ciou)  # 1. respond_bbox作为mask，有物体才计算xxxiou_loss\n","\n","        # 2. respond_bbox作为mask，有物体才计算类别loss\n","        prob_loss = respond_bbox *  tf.nn.sigmoid_cross_entropy_with_logits(label_prob, conv_raw_prob)\n","        # 等价于\n","        # pred_prob = pred[:, :, :, :, 5:]\n","        # prob_pos_loss = label_prob * (0 - K.log(pred_prob + 1e-9))\n","        # prob_neg_loss = (1 - label_prob) * (0 - K.log(1 - pred_prob + 1e-9))\n","        # prob_mask = tf.tile(respond_bbox, [1, 1, 1, 1, num_class])\n","        # prob_loss = prob_mask * (prob_pos_loss + prob_neg_loss)\n","\n","        # 3. xxxiou_loss和类别loss比较简单。重要的是conf_loss，是一个二值交叉熵损失\n","        # 分两步：第一步是确定 grid_h * grid_w * 3 个预测框 哪些作为反例；第二步是计算二值交叉熵损失。\n","        expand_pred_xywh = pred_xywh[:, :, :, :, np.newaxis, :]  # 扩展为(?, grid_h, grid_w, 3,   1, 4)\n","        expand_bboxes = y_batch_bbox[:, np.newaxis, np.newaxis, np.newaxis, :, :]  # 扩展为(?,      1,      1, 1, 70, 4)\n","        iou = bbox_iou(expand_pred_xywh,\n","                       expand_bboxes)  # 所有格子的3个预测框 分别 和  70个ground truth  计算iou。   (?, grid_h, grid_w, 3, 70)\n","        max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1),\n","                                 axis=-1)  # 与70个ground truth的iou中，保留最大那个iou。  (?, grid_h, grid_w, 3, 1)\n","\n","        # respond_bgd代表  这个分支输出的 grid_h * grid_w * 3 个预测框是否是 反例（背景）\n","        # label有物体，respond_bgd是0。 没物体的话：如果和某个gt(共70个)的iou超过iou_loss_thresh，respond_bgd是0；如果和所有gt(最多70个)的iou都小于iou_loss_thresh，respond_bgd是1。\n","        # respond_bgd是0代表有物体，不是反例（或者是忽略框）；  权重respond_bgd是1代表没有物体，是反例。\n","        # 有趣的是，模型训练时由于不断更新，对于同一张图片，两次预测的 grid_h * grid_w * 3 个预测框（对于这个分支输出）  是不同的。用的是这些预测框来与gt计算iou来确定哪些预测框是反例。\n","        # 而不是用固定大小（不固定位置）的先验框。\n","        respond_bgd = (1.0 - respond_bbox) * tf.cast(max_iou < IOU_LOSS_THRESH, tf.float32)\n","\n","        # 二值交叉熵损失\n","        pos_loss = respond_bbox * (0 - K.log(pred_conf + 1e-9))\n","        neg_loss = respond_bgd * (0 - K.log(1 - pred_conf + 1e-9))\n","\n","        conf_loss = pos_loss + neg_loss\n","        # 回顾respond_bgd，某个预测框和某个gt的iou超过iou_loss_thresh，不被当作是反例。在参与“预测的置信位 和 真实置信位 的 二值交叉熵”时，这个框也可能不是正例(label里没标这个框是1的话)。这个框有可能不参与置信度loss的计算。\n","        # 这种框一般是gt框附近的框，或者是gt框所在格子的另外两个框。它既不是正例也不是反例不参与置信度loss的计算。（论文里称之为ignore）\n","\n","        ciou_loss = tf.reduce_mean(tf.reduce_sum(ciou_loss, axis=[1, 2, 3, 4]))  # 每个样本单独计算自己的ciou_loss，再求平均值\n","        conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1, 2, 3, 4]))  # 每个样本单独计算自己的conf_loss，再求平均值\n","        prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1, 2, 3, 4]))  # 每个样本单独计算自己的prob_loss，再求平均值\n","\n","        return ciou_loss, conf_loss, prob_loss    \n","\n","    return yolo_loss\n","def decode(conv_output, anchors, stride, num_class):\n","    conv_shape       = tf.shape(conv_output)\n","    batch_size       = conv_shape[0]\n","    output_size      = conv_shape[1]\n","    anchor_per_scale = len(anchors)\n","    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, anchor_per_scale, 5 + num_class))\n","    conv_raw_dxdy = conv_output[:, :, :, :, 0:2]\n","    conv_raw_dwdh = conv_output[:, :, :, :, 2:4]\n","    conv_raw_conf = conv_output[:, :, :, :, 4:5]\n","    conv_raw_prob = conv_output[:, :, :, :, 5: ]\n","    y = tf.tile(tf.range(output_size, dtype=tf.int32)[:, tf.newaxis], [1, output_size])\n","    x = tf.tile(tf.range(output_size, dtype=tf.int32)[tf.newaxis, :], [output_size, 1])\n","    xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n","    xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, anchor_per_scale, 1])\n","    xy_grid = tf.cast(xy_grid, tf.float32)\n","    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * stride\n","    pred_wh = (tf.exp(conv_raw_dwdh) * anchors)\n","    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n","    pred_conf = tf.sigmoid(conv_raw_conf)\n","    pred_prob = tf.sigmoid(conv_raw_prob)\n","    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n","def loss_layer(conv, pred, label, bboxes, stride, num_class, iou_loss_thresh):\n","    conv_shape = tf.shape(conv)\n","    batch_size = conv_shape[0]\n","    output_size = conv_shape[1]\n","    input_size = stride * output_size\n","    conv = tf.reshape(conv, (batch_size, output_size, output_size,\n","                             3, 5 + num_class))\n","    conv_raw_prob = conv[:, :, :, :, 5:]\n","\n","    pred_xywh = pred[:, :, :, :, 0:4]\n","    pred_conf = pred[:, :, :, :, 4:5]\n","\n","    label_xywh = label[:, :, :, :, 0:4]\n","    respond_bbox = label[:, :, :, :, 4:5]\n","    label_prob = label[:, :, :, :, 5:]\n","\n","    ciou = tf.expand_dims(bbox_ciou(pred_xywh, label_xywh), axis=-1)  # (8, 13, 13, 3, 1)\n","    input_size = tf.cast(input_size, tf.float32)\n","\n","    # 每个预测框xxxiou_loss的权重 = 2 - (ground truth的面积/图片面积)\n","    bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2)\n","    ciou_loss = respond_bbox * bbox_loss_scale * (1 - ciou)  # 1. respond_bbox作为mask，有物体才计算xxxiou_loss\n","\n","    # 2. respond_bbox作为mask，有物体才计算类别loss\n","    prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=label_prob, logits=conv_raw_prob)\n","    # 等价于\n","    # pred_prob = pred[:, :, :, :, 5:]\n","    # prob_pos_loss = label_prob * (0 - K.log(pred_prob + 1e-9))\n","    # prob_neg_loss = (1 - label_prob) * (0 - K.log(1 - pred_prob + 1e-9))\n","    # prob_mask = tf.tile(respond_bbox, [1, 1, 1, 1, num_class])\n","    # prob_loss = prob_mask * (prob_pos_loss + prob_neg_loss)\n","\n","\n","    # 3. xxxiou_loss和类别loss比较简单。重要的是conf_loss，是一个二值交叉熵损失\n","    # 分两步：第一步是确定 grid_h * grid_w * 3 个预测框 哪些作为反例；第二步是计算二值交叉熵损失。\n","    expand_pred_xywh = pred_xywh[:, :, :, :, np.newaxis, :]  # 扩展为(?, grid_h, grid_w, 3,   1, 4)\n","    expand_bboxes = bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :]  # 扩展为(?,      1,      1, 1, 70, 4)\n","    iou = bbox_iou(expand_pred_xywh, expand_bboxes)  # 所有格子的3个预测框 分别 和  70个ground truth  计算iou。   (?, grid_h, grid_w, 3, 70)\n","    max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1), axis=-1)  # 与70个ground truth的iou中，保留最大那个iou。  (?, grid_h, grid_w, 3, 1)\n","\n","    # respond_bgd代表  这个分支输出的 grid_h * grid_w * 3 个预测框是否是 反例（背景）\n","    # label有物体，respond_bgd是0。 没物体的话：如果和某个gt(共70个)的iou超过iou_loss_thresh，respond_bgd是0；如果和所有gt(最多70个)的iou都小于iou_loss_thresh，respond_bgd是1。\n","    # respond_bgd是0代表有物体，不是反例（或者是忽略框）；  权重respond_bgd是1代表没有物体，是反例。\n","    # 有趣的是，模型训练时由于不断更新，对于同一张图片，两次预测的 grid_h * grid_w * 3 个预测框（对于这个分支输出）  是不同的。用的是这些预测框来与gt计算iou来确定哪些预测框是反例。\n","    # 而不是用固定大小（不固定位置）的先验框。\n","    # respond_bgd = (1.0 - respond_bbox) * tf.cast(max_iou < iou_loss_thresh, tf.float32)\n","    respond_bgd = (1.0 - respond_bbox)\n","\n","    # 二值交叉熵损失\n","    pos_loss = respond_bbox * (0 - K.log(pred_conf + 1e-9))\n","    neg_loss = respond_bgd  * (0 - K.log(1 - pred_conf + 1e-9))\n","\n","    conf_loss = pos_loss + neg_loss\n","    # 回顾respond_bgd，某个预测框和某个gt的iou超过iou_loss_thresh，不被当作是反例。在参与“预测的置信位 和 真实置信位 的 二值交叉熵”时，这个框也可能不是正例(label里没标这个框是1的话)。这个框有可能不参与置信度loss的计算。\n","    # 这种框一般是gt框附近的框，或者是gt框所在格子的另外两个框。它既不是正例也不是反例不参与置信度loss的计算。（论文里称之为ignore）\n","\n","    ciou_loss = tf.reduce_mean(tf.reduce_sum(ciou_loss, axis=[1, 2, 3, 4]))  # 每个样本单独计算自己的ciou_loss，再求平均值\n","    conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1, 2, 3, 4]))  # 每个样本单独计算自己的conf_loss，再求平均值\n","    prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1, 2, 3, 4]))  # 每个样本单独计算自己的prob_loss，再求平均值\n","\n","    return ciou_loss, conf_loss, prob_loss\n","\n","def decode_train2(conv_output, output_size, NUM_CLASS, STRIDES, ANCHORS, XYSCALE):\n","    conv_output = tf.reshape(conv_output,\n","                             (tf.shape(conv_output)[0], output_size, output_size, 3, 5 + NUM_CLASS))\n","\n","    # conv_raw_dxdy, conv_raw_dwdh, conv_raw_conf, conv_raw_prob = tf.split(conv_output, (2, 2, 1, NUM_CLASS),\n","    #                                                                       axis=-1)\n","    conv_raw_dxdy = conv_output[:, :, :, :, 0:2]\n","    conv_raw_dwdh = conv_output[:, :, :, :, 2:4]\n","    conv_raw_conf = conv_output[:, :, :, :, 4:5]\n","    conv_raw_prob = conv_output[:, :, :, :, 5:]\n","\n","    # xy_grid = tf.meshgrid(tf.range(output_size), tf.range(output_size))\n","    # xy_grid = tf.expand_dims(tf.stack(xy_grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n","    # xy_grid = tf.tile(tf.expand_dims(xy_grid, axis=0), [tf.shape(conv_output)[0], 1, 1, 3, 1])\n","    # xy_grid = tf.cast(xy_grid, tf.float32)\n","    y = tf.tile(tf.range(output_size, dtype=tf.int32)[:, tf.newaxis], [1, output_size])\n","    x = tf.tile(tf.range(output_size, dtype=tf.int32)[tf.newaxis, :], [output_size, 1])\n","    xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n","    xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [tf.shape(conv_output)[0], 1, 1, 3, 1])\n","    xy_grid = tf.cast(xy_grid, tf.float32)\n","\n","    # pred_xy = ((tf.sigmoid(conv_raw_dxdy) * XYSCALE) - 0.5 * (XYSCALE - 1) + xy_grid) * STRIDES\n","    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES\n","    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS)\n","    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n","\n","    pred_conf = tf.sigmoid(conv_raw_conf)\n","    # pred_prob = tf.sigmoid(conv_raw_prob)\n","\n","    return tf.concat([pred_xywh, pred_conf, conv_raw_prob], axis=-1)\n","\n","# x_batch, y_batch = X, y = data_gen.__getitem__(0)\n","\n","\n","losses = [yolo_loss_wrapper(input_shape=(416, 416), \n","                  STRIDES=[8, 16, 32][i], \n","                  NUM_CLASS=NUM_CLASS,\n","                  ANCHORS=anchors.reshape(3, 3, 2)[i], \n","                  XYSCALES=[1., 1., 1.][i], \n","                  IOU_LOSS_THRESH=0.5) for i in range(3)]\n","def yolo_loss2(args, num_classes, iou_loss_thresh, anchors):\n","    conv_lbbox = args[2]   # (?, ?, ?, 3*(num_classes+5))\n","    conv_mbbox = args[1]   # (?, ?, ?, 3*(num_classes+5))\n","    conv_sbbox = args[0]   # (?, ?, ?, 3*(num_classes+5))\n","    label_sbbox = args[3]   # (?, ?, ?, 3, num_classes+5)\n","    label_mbbox = args[4]   # (?, ?, ?, 3, num_classes+5)\n","    label_lbbox = args[5]   # (?, ?, ?, 3, num_classes+5)\n","    true_bboxes = args[6]   # (?, 50, 4)\n","    pred_sbbox = decode(conv_sbbox, anchors[0], 8, num_classes)\n","    pred_mbbox = decode(conv_mbbox, anchors[1], 16, num_classes)\n","    pred_lbbox = decode(conv_lbbox, anchors[2], 32, num_classes)\n","    # pred_sbbox = decode_train2(conv_sbbox, 52, num_classes, 8, anchors[0], 1) # decode(conv_sbbox, anchors[0], 8, num_classes)\n","    # pred_mbbox = decode_train2(conv_mbbox, 26, num_classes, 16, anchors[1], 1) # decode(conv_mbbox, anchors[1], 16, num_classes)\n","    # pred_lbbox = decode_train2(conv_lbbox, 13, num_classes, 32, anchors[2], 1) # decode(conv_lbbox, anchors[2], 32, num_classes)\n","    sbbox_ciou_loss, sbbox_conf_loss, sbbox_prob_loss = loss_layer(conv_sbbox, pred_sbbox, label_sbbox, true_bboxes, 8, num_classes, iou_loss_thresh)\n","    mbbox_ciou_loss, mbbox_conf_loss, mbbox_prob_loss = loss_layer(conv_mbbox, pred_mbbox, label_mbbox, true_bboxes, 16, num_classes, iou_loss_thresh)\n","    lbbox_ciou_loss, lbbox_conf_loss, lbbox_prob_loss = loss_layer(conv_lbbox, pred_lbbox, label_lbbox, true_bboxes, 32, num_classes, iou_loss_thresh)\n","\n","    ciou_loss = lbbox_ciou_loss + sbbox_ciou_loss + mbbox_ciou_loss\n","    conf_loss = lbbox_conf_loss + sbbox_conf_loss + mbbox_conf_loss\n","    prob_loss = lbbox_prob_loss + sbbox_prob_loss + mbbox_prob_loss\n","    # print(ciou_loss, conf_loss, prob_loss)\n","    return ciou_loss, conf_loss, prob_loss\n","\n","# # In[31]:\n","INIT_LR = 1e-4 # 1e-6\n","FINAL_LR = 1e-4 # 1e-8\n","opt = tf.keras.optimizers.Adam(lr=1e-4)\n","opt2 = tf.keras.optimizers.Adam(lr=1e-4)\n","opt3 = tf.keras.optimizers.Adam(lr=1e-4)\n","steps_per_epoch = len(lines) // BS\n","warmup_epochs = 20\n","warmup_steps = warmup_epochs * steps_per_epoch\n","global_steps = 0\n","first_stage_epoch = 200\n","second_stage_epoch = 300\n","total_steps = (first_stage_epoch + second_stage_epoch) * steps_per_epoch\n","\n","y_true = [\n","    tf.keras.layers.Input(name='input_2', shape=(52, 52, 3, (NUM_CLASS + 5))),  # label_sbbox\n","    tf.keras.layers.Input(name='input_3', shape=(26, 26, 3, (NUM_CLASS + 5))),  # label_mbbox\n","    tf.keras.layers.Input(name='input_4', shape=(13, 13, 3, (NUM_CLASS + 5))),  # label_lbbox\n","    tf.keras.layers.Input(name='input_5', shape=(100, 4)),             # true_bboxes\n","]\n","loss_list = tf.keras.layers.Lambda(yolo_loss2, name='yolo_loss',\n","                        arguments={'num_classes': NUM_CLASS, 'iou_loss_thresh': 0.5,\n","                                    'anchors': anchors.reshape((3, 3, 2))})([*model.yolo_model.output, *y_true])\n","model2 = tf.keras.models.Model([model.yolo_model.input, *y_true], loss_list)\n","\n","model2.compile(loss={'yolo_loss': lambda y_true, y_pred: y_pred}, optimizer=tf.keras.optimizers.Adam(lr=1e-4))\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRGaSIyn_MWf","colab_type":"code","colab":{}},"source":["def train_step(x_batch, y_batch_tensor, y_batch_bbox):\n","    with tf.GradientTape() as tape_giou, tf.GradientTape() as tape_conf, tf.GradientTape() as tape_prob:\n","        predict = model.yolo_model(x_batch)\n","        # total_giou_loss = 0\n","        # total_conf_loss = 0\n","        # total_prob_loss = 0\n","        # for i in range(0,3):\n","        #     loss_func = losses[i]\n","        #     giou_loss, conf_loss, prob_loss = loss_func(y_batch_tensor[i], predict[i], y_batch_bbox)\n","        #     total_giou_loss += giou_loss\n","        #     total_conf_loss += conf_loss\n","        #     total_prob_loss += prob_loss\n","        #     print(i, total_giou_loss, total_conf_loss, total_prob_loss)\n","\n","        giou_loss0, conf_loss0, prob_loss0 = losses[0](y_batch_tensor[0], predict[0], y_batch_bbox)\n","        giou_loss1, conf_loss1, prob_loss1 = losses[1](y_batch_tensor[1], predict[1], y_batch_bbox)\n","        giou_loss2, conf_loss2, prob_loss2 = losses[2](y_batch_tensor[2], predict[2], y_batch_bbox)\n","        total_giou_loss = giou_loss0 + giou_loss1 + giou_loss2\n","        total_conf_loss = conf_loss0 + conf_loss1 + conf_loss2\n","        total_prob_loss = prob_loss0 + prob_loss1 + prob_loss2\n","        print(total_giou_loss, total_conf_loss, total_prob_loss)\n","        # total_loss = total_giou_loss + total_conf_loss + total_prob_loss  # total_giou_loss + total_conf_loss + total_prob_loss\n","    gradients1 = tape_giou.gradient(total_giou_loss, model.yolo_model.trainable_variables)\n","    gradients2 = tape_conf.gradient(total_conf_loss, model.yolo_model.trainable_variables)\n","    gradients3 = tape_prob.gradient(total_prob_loss, model.yolo_model.trainable_variables)\n","    opt.apply_gradients(zip(gradients1, model.yolo_model.trainable_variables))\n","    opt2.apply_gradients(zip(gradients2, model.yolo_model.trainable_variables))\n","    opt3.apply_gradients(zip(gradients3, model.yolo_model.trainable_variables))\n","\n","logs = np.array([])\n","for epoch in range(1000):\n","    for x_batch, y_batch_tensor, y_batch_bbox in data_gen:\n","        y_true = [np.zeros(BS), np.zeros(BS), np.zeros(BS)]\n","        # print('train on batch ', y_batch_tensor[0].shape)\n","        losses = model2.train_on_batch([x_batch, *y_batch_tensor, y_batch_bbox], y_true)\n","        loss = losses[0]\n","        print(f'epoch {epoch} losses ' , loss)\n","        if len(logs) > 0 and loss < np.min(logs):\n","            model.yolo_model.save('/content/drive/My Drive/yolov4-giou.h5')\n","        logs = np.append(logs, loss)\n","        # train_step(x_batch, y_batch_tensor, y_batch_bbox)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqxqbu_XVLa9","colab_type":"code","colab":{}},"source":["# model2.fit(data_gen, \n","#             steps_per_epoch=1,\n","#            epochs=10000\n","#            )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W6iv_-gHmSte","colab_type":"code","colab":{}},"source":["model.predict('/content/drive/My Drive/yolo-v4-tf.keras/dataset/train_img2/test3.jpg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3H2ukQIB4gc","colab_type":"code","colab":{}},"source":["i = np.random.randint(0, 300)\n","path = f'/content/drive/My Drive/yolo-v4-tf.keras/dataset/train_img/BloodImage_00000.jpg'\n","print(path)\n","model.predict(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"95zRzZHjW9aS","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}